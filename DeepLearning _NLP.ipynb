{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    hello = tf.constant('Hello, Tensorflow!')\n",
    "    print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global uniq_train_words\n",
    "uniq_train_words=set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of reviews:  <class 'list'>\n",
      "Total number of reviews:  2003\n",
      "Text at index 6:\n",
      "  b\"It's a colorful slasher movie. That's about it.<br /><br />It has the mystery element that SCREAM made so popular in slasher movies, but I never care for such things. Figuring out who's the bad guy is not that interesting considering the clues are all misleading anyway.<br /><br />The death scenes were inventive and gorey, bringing back memories of 80's horror movies like Friday the 13th. <br /><br />Another nice thing about this movie is that it's hard to pinpoint the surviving girl, unlike in SCREAM and IKWYDLS where it was obvious. <br /><br />People who don't like slasher movies won't like this movie. As simple as that. I truly enjoyed it and I plan to watch it again while waiting for more of the same. <br /><br />--MB\"\n",
      "Label of the review at Index 6:  1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "# Read training files\n",
    "reviews_set = load_files(\"C:/Users/admin/Desktop/data/\")\n",
    "# Lets get training reviews and training labels in sepearate lists\n",
    "reviews, labels = reviews_set.data, reviews_set.target\n",
    "\n",
    "# Let's understand the two lists: reviews (text_train) and their labels (y_train)\n",
    "print(\"Data type of reviews: \",type(reviews))\n",
    "print(\"Total number of reviews: \",len(reviews))\n",
    "print(\"Text at index 6:\\n \", reviews[6])\n",
    "print(\"Label of the review at Index 6: \",labels[6])\n",
    "# 0 for negative and 1 for positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rev, test_rev,train_lbls, test_lbls = train_test_split(reviews, labels, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#Custom function for text noise removal and stemming\n",
    "def noise_removal(text_data, isTraining=True):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    punctuation_list=list(string.punctuation)\n",
    "    # additional punctuation marks\n",
    "    punctuation_list.append(\"--\") \n",
    "    punctuation_list.append(\"''\")\n",
    "    punctuation_list.append(\"``\")\n",
    "    text_data=text_data.replace(\"<br />\", \" \") \n",
    "    # some  stop words\n",
    "    stop_words=['a','an','he','she','it','am','will','have','has','i','you','me','\\'s','``','\\'','(',')','*****','...']\n",
    "    noise_list=punctuation_list +stop_words\n",
    "    # making sure in testing we are keeping only words in training and removing noise in both training and testing\n",
    "    #first tokenize, if not in noise_list, stem\n",
    "    filtered_words=[stemmer.stem(w) for w in nltk.word_tokenize(text_data) if w not in noise_list]\n",
    "       \n",
    "    if isTraining==True:\n",
    "        for w in filtered_words:\n",
    "            uniq_train_words.add(w )\n",
    "    else:# during testing\n",
    "        filtered_words=[w for w in filtered_words if w in uniq_train_words]\n",
    "        \n",
    "    return  \" \".join(filtered_words) # convert the list of tokenize words to a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(reviews,isTraining=True):\n",
    "    reviews= [noise_removal(text.decode(),isTraining) for text in reviews]\n",
    "    # Integer encode the documents\n",
    "    vocab_size=len(uniq_train_words)\n",
    "    print(vocab_size)\n",
    "    \n",
    "    print (reviews[0])\n",
    "    encoded_reviews = [one_hot(review, vocab_size) for review in reviews]\n",
    "    \n",
    "    # pad documents to a max length of n words\n",
    "    padded_reviews = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')\n",
    "    return padded_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
